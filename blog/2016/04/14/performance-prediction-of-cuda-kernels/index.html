
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Performance Prediction of CUDA Kernels - Curious Explorations</title>
  <meta name="author" content="kmmankad">

  
  <meta name="description" content="This post is going to be more loud thinking, and less code - (&lsquo;cuz there isn&rsquo;t any yet :) ) NVIDIA CUDA is supported on a wide range of &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://kmmankad.github.io/blog/2016/04/14/performance-prediction-of-cuda-kernels">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Curious Explorations" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet" type="text/css">
<!--- MathJax Configuration -->
<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Curious Explorations</a></h1>
  
    <h2>A hardware/software hacker's (b)log.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscribe" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS" target="_blank"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewbox="0 0 100 100"><path class="social" d="M 13.310204,73.332654 C 5.967347,73.332654 0,79.322448 0,86.621428 c 0,7.338776 5.967347,13.262246 13.310204,13.262246 7.370408,0 13.328572,-5.92245 13.328572,-13.262246 0,-7.29898 -5.958164,-13.288774 -13.328572,-13.288774 z M 0.01530612,33.978572 V 53.143878 C 12.493878,53.143878 24.229592,58.02347 33.068368,66.865306 41.894898,75.685714 46.767346,87.47449 46.767346,100 h 19.25 C 66.017346,63.592858 36.4,33.979592 0.01530612,33.978572 l 0,0 z M 0.03877552,0 V 19.17449 C 44.54796,19.17551 80.77551,55.437756 80.77551,100 H 100 C 100,44.87653 55.15102,0 0.03877552,0 z"></path></svg></a></li>
  
</ul>
  
  
  
  
  
<ul class="subscribe">
  <li><a href="https://github.com/kmmankad" rel="subscribe-github" title="@kmmankad on GitHub" target="_blank"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewbox="0 0 100 100"><path class="social" d="M 50,0 C 22.385714,0 0,22.385714 0,50 0,77.614286 22.385714,100 50,100 77.614286,100 100,77.614286 100,50 100,22.385714 77.614286,0 50,0 z m 29.692858,79.692858 c -3.859184,3.859182 -8.351022,6.887754 -13.35,9.00306 -1.27041,0.536736 -2.560204,1.009184 -3.867348,1.415306 v -7.493878 c 0,-3.938774 -1.35102,-6.835714 -4.053062,-8.690816 1.692858,-0.163264 3.24694,-0.390816 4.663266,-0.683672 1.416326,-0.292858 2.913266,-0.716328 4.491838,-1.27041 1.57857,-0.55408 2.994896,-1.213264 4.247958,-1.97755 1.253062,-0.765306 2.458164,-1.758164 3.613266,-2.978572 1.155102,-1.220408 2.12449,-2.604082 2.905102,-4.15 0.780612,-1.545918 1.4,-3.40204 1.855102,-5.566326 0.455102,-2.164286 0.683674,-4.54898 0.683674,-7.153062 0,-5.045918 -1.643878,-9.341836 -4.931634,-12.890816 C 77.44796,33.35 77.285714,29.10204 75.463266,24.512244 l -1.22143,-0.145918 c -0.845918,-0.09796 -2.368366,0.260204 -4.565306,1.07449 -2.196938,0.814286 -4.663264,2.14796 -7.396938,4.004082 -3.87449,-1.07449 -7.893878,-1.611224 -12.061224,-1.611224 -4.19898,0 -8.203062,0.536734 -12.012246,1.611224 -1.72449,-1.17245 -3.361224,-2.139796 -4.907142,-2.905102 C 31.753062,25.77449 30.516326,25.254082 29.587756,24.97653 28.660204,24.7 27.79796,24.528572 27,24.463266 c -0.79796,-0.0653 -1.310204,-0.08062 -1.537756,-0.04898 -0.22755,0.03164 -0.390816,0.0653 -0.487754,0.09796 -1.82347,4.62245 -1.985714,8.87143 -0.487756,12.743878 -3.287754,3.54796 -4.931632,7.844898 -4.931632,12.890816 0,2.604082 0.227552,4.988776 0.683674,7.153062 0.456122,2.164286 1.07449,4.020408 1.855102,5.566326 0.780612,1.545918 1.75,2.929592 2.905102,4.15 1.155102,1.220408 2.360204,2.213266 3.613264,2.978572 1.253062,0.766326 2.669388,1.42449 4.24796,1.97755 1.578572,0.554082 3.07551,0.976532 4.491836,1.27041 1.416328,0.292856 2.970408,0.521428 4.663266,0.683672 -2.669388,1.82347 -4.004082,4.720408 -4.004082,8.690816 v 7.639796 C 36.536734,89.818368 35.083674,89.3 33.656122,88.695918 c -4.99898,-2.115306 -9.490816,-5.143878 -13.35,-9.00306 -3.859184,-3.859184 -6.887754,-8.351022 -9.00306,-13.35 C 9.1163263,61.171428 8.0071428,55.67347 8.0071428,50 c 0,-5.67347 1.1091835,-11.171428 3.2969392,-16.342858 2.115306,-4.998978 5.143878,-9.490816 9.00306,-13.35 3.859184,-3.859182 8.351022,-6.887754 13.35,-9.00306 C 38.828572,9.1163266 44.32653,8.0071428 50,8.0071428 c 5.67347,0 11.171428,1.1091838 16.342858,3.2969392 5,2.115306 9.490816,5.143878 13.35,9.00306 3.859182,3.859184 6.887754,8.351022 9.00306,13.35 2.186736,5.17245 3.295918,10.67041 3.295918,16.342858 0,5.672448 -1.109182,11.171428 -3.296938,16.342858 -2.115306,4.998978 -5.143878,9.490816 -9.00204,13.35 l 0,0 z"></path></svg></a></li>
</ul>
  
  
  
  
  
  
  
  
    
      <form action="https://www.google.com/search" method="get">
        <fieldset role="search">
          <input type="hidden" name="sitesearch" value="kmmankad.github.io" />
    
          <input class="search" type="text" name="q" results="0" placeholder="Search"/>
        </fieldset>
      </form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      
        <h1 class="entry-title">Performance Prediction of CUDA Kernels</h1>
      
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-14T06:38:26+05:30'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:38 am</span></time>
        
        
      </p>
    
  </header>


<div class="entry-content"><p>This post is going to be more loud thinking, and less code - (&lsquo;cuz there isn&rsquo;t any yet :) )</p>

<p>NVIDIA CUDA is supported on a wide range of hardware platforms they sell, right from their Tegra Mobile SoCs, notebook GPUs (thats what I have right now), desktop and workstation class GPUs, server class Tesla series, the most recent (and powerful) of which is the mighty <a href="http://www.nvidia.com/object/tesla-p100.html">Tesla P100</a>.</p>

<p>Over side a wide range of hardware and their relative cost, there must be a way for a potential buyer or user to establish (even approximately) how much $$ spent would result in what improvement in performance of their CUDA or OpenACC accelerated code. A couple of ways come to mind on how to achieve this, listed below.</p>

<ol>
<li><p>Create C++/SystemC models of <em>all</em> these available GPUs, and run your program on these to artifically judge their performance. Or,</p></li>
<li><p>Maybe they(NVDA) could provide the capability to &lsquo;test-drive&rsquo; these GPUs, say in the cloud for some trial period for users to judge their potential return on hardware investment. I recall seeing a link for something this somewhere in <a href="https://developer.nvidia.com/cuda-zone">CUDAZone</a> - though only for their Tesla M40 series. My guess is this service is made available via an <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html">GPU enabled AWS instance</a> that actually has an M40. So this idea could work, but is not scalable because we&rsquo;d need a whole room full of the entire product portfolio that we need to then allow N users access to. Bleh.</p></li>
<li><p>Hey, its April 2016. No, its not super relevant other than the fact that it&rsquo;ll mark a few months of my machine learning experience and that the world has just been introduced to DGX-1. More the latter :) The point I&rsquo;m making is we could adopt a <strong>Machine Learning based approach</strong>! Let me summarize this below:</p>

<ul>
<li><p>Create a feature vector for each CUDA kernel - This could be a bunch of stats from <a href="http://docs.nvidia.com/cuda/profiler-users-guide/#axzz46EPgphj2">nvprof</a>, NVIDIA&rsquo;s handy univeral profiler for all GPGPU code. Selecting the right features is the first step here. We&rsquo;d then do all the usual tricks with it. Normalize, scale etc, etc.</p></li>
<li><p>Then, once we can represent any CUDA kernel in the world with a feature vector, we&rsquo;d now need the data. Now the labelled training data in this case would be pairs of features-wallclock time. We could have the same kernels run on a range of hardware and generate the full spread of traning data. Given that nvprof already knows a whole lot about your kernel, this data collection would be best handled by it. Maybe, and I&rsquo;m getting crazy here - we could even crowdsource that data! Many programs already do that type of thing for usage data, so NVIDIA could add that to nvprof (&lsquo;<em>Do you want to submit anonymous report stats to NVIDIA? Click Yes to help the machines rise.</em>&rsquo;) That way, a ton of data would pour in (and keep pouring in) from customers, developers and datacenters all around the world. (Well thats only if the option to upload said data is not at an annoying point - like firefox meekly asks after it crashes. Do you want to report this.. <em>angry shouts</em> I dont care about you, damn mozilla! I just lost all my browsing data!)
I see the availability of data as the real bottleneck here for someone to create that. Once again, an example of the fact that <a href="https://medium.com/summer-ai/ai-s-big-trade-secret-a0d59110d6e3#.7z3h0ak3t">advances in machine learning are not going to come from people with the best ideas, algorithms or even the best hardware - but by who has the data</a>. Information is power.</p></li>
<li><p>Say you have this data. Then you could run your favorite regression algorithm to predict this! Bloody Brilliant! ..the added awesomeness comes from the fact that the crowd sourced data is like free fuel for this prediction engine!</p></li>
</ul>
</li>
</ol>


<p>But, I dont have that data, or the hardware to collect it. So, this idea kind of hits a dead end but I&rsquo;m leaving it around on the blog for now. I wonder if I could publish someplace&hellip;</p>
</div>


  <footer>
    <p class="meta">
      
  



  <span class="byline author vcard">Authored by <span class="fn">
  
    kmmankad
  
  </span></span>


      




<time class='entry-date' datetime='2016-04-14T06:38:26+05:30'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:38 am</span></time>
      
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://kmmankad.github.io/blog/2016/04/14/performance-prediction-of-cuda-kernels/" data-via="" data-counturl="http://kmmankad.github.io/blog/2016/04/14/performance-prediction-of-cuda-kernels/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2016/04/03/openacc-analyze/" title="Previous Post: OpenACC: Analyze, Express, Tweak! - Part 1">&laquo; OpenACC: Analyze, Express, Tweak! - Part 1</a>
      
      
    </p>
  </footer>
</article>


</div>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - kmmankad -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/lucaslew/whitespace">Whitespace</a></span>
</p>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
