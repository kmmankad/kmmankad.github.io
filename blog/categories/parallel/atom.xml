<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Parallel, | Curious Explorations]]></title>
  <link href="http://kmmankad.github.io/blog/categories/parallel/atom.xml" rel="self"/>
  <link href="http://kmmankad.github.io/"/>
  <updated>2016-04-04T22:13:24+05:30</updated>
  <id>http://kmmankad.github.io/</id>
  <author>
    <name><![CDATA[kmmankad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenACC: Analyze, Express, Tweak!]]></title>
    <link href="http://kmmankad.github.io/blog/2016/04/03/openacc-analyze/"/>
    <updated>2016-04-03T11:22:49+05:30</updated>
    <id>http://kmmankad.github.io/blog/2016/04/03/openacc-analyze</id>
    <content type="html"><![CDATA[<h2>Whats OpenACC?</h2>

<p>From <a href="http://developer.nvidia.com/openacc">http://developer.nvidia.com/openacc</a>:</p>

<blockquote><p>OpenACC is a directive-based programming model designed to provide a simple yet powerful approach to accelerators without significant programming effort.</p></blockquote>

<p>What that is means is, you can pickup existing code written for an x86 CPU, and add some compiler <code>#pragmas</code>, compile with an OpenACC capable compiler - and voila! You get accelerated binaries for a range of hardware accelerators - Nvidia GPUs, AMD GPUs and even Intel multi-core CPUs. Thats really the USP of OpenACC - a single copy of the source code will deliver performance portability across this range of hardware platforms.
So, to be successful with OpenACC all you need are strong concepts in parallel programming, some know-how about OpenACC syntax and you’re good to go! You dont need to really know too many lower level hardware details with OpenACC, as opposed to, maybe CUDA C. However, this is a double edged sword - I will revisit this later in this post.</p>

<p>There are some really good tutorials on OpenACC itself available online:<br/>
1. <a href="https://devblogs.nvidia.com/parallelforall/getting-started-openacc/">Jeff Larkin&rsquo;s post on the Parallel Forall blog</a><br/>
2. Jeff Larkin&rsquo;s sessions from GTC 2013 - recordings on Youtube here : <a href="https://www.youtube.com/watch?v=0e5TiwZd_wE">Part1</a> <a href="https://www.youtube.com/watch?v=YueszvniRUE">Part2</a></p>

<p>The recommended approach for parallelism anywhere is to:<br/>
1. Try and use existing parallel optimized libraries like cuBLAS, cuDNN etc. if they exist for your application.<br/>
2. If you dont get those, try OpenACC on your code. That should get you about 80% of the maximum available performance.<br/>
<em>Ofcourse, that is a very rough number and is subject to, you guessed it, your code and the GPU hardware you&rsquo;re running.</em>
3. Roll your own CUDA kernels. This is definitely the most involved of the 3 options, but it will allow you to squeeze
every last drop of that good perf juice from your software and hardware.</p>

<p>OpenACC tutorials online often use the Jacobi Iteration/sAXPY example to demonstrate OpenACC, but all that those examples teach us are syntax constructs. However, if you use OpenACC in the real world, you’ll know it&rsquo;s all about how you analyze your source code, understand its scope for parallelism and finally express that formally via OpenACC syntax. What this post is really about is about the analysis of a simple program, which is hopefully a little less trivial than the Jacobi type examples all over the net.</p>

<p>First off, some logistics about tool installation and setup.</p>

<ul>
<li>We will be using the PGI Compiler today, which you can get from the <a href="http://www.pgroup.com/support/download_pgi2016.php?view=current">PGroup&rsquo;s site</a></li>
<li>You can also download the <a href="https://developer.nvidia.com/openacc-toolkit">OpenACC toolkit from NVIDIA</a></li>
</ul>


<p>If you have everything correctly setup, try <code>pgcc --version</code> as shown below
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>PGI Workstation 15.10 <span class="o">(</span>64<span class="o">)</span>
</span><span class='line'>PGI<span class="nv">$ </span>pgcc <span class="p">&amp;</span>ndash<span class="p">;</span>version&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;pgcc 15.10-0 64-bit target on x86-64 Windows -tp haswell
</span><span class='line'>The Portland Group - PGI Compilers and Tools
</span><span class='line'>Copyright <span class="p">&amp;</span>copy<span class="p">;</span> 2015, NVIDIA CORPORATION.  All rights reserved.
</span></code></pre></td></tr></table></div></figure></p>

<p>Now, onto our target today - a subroutine that converts a hexadecimal string to base64. I picked this up from the <a href="http://cryptopals.com/">matasano cryptography challenges</a> I&rsquo;m attempting on the side and decided it&rsquo;d be a good example for this tutorial.</p>

<p>Heres a brief overview of the algorithm itself:
1. Take 3 bytes of input hex data at a time,
2. Do some bitwise concatenation (shift and OR) and get indexes of 4 base64 characters that these 3 bytes are encoded into
3. Lookup the actual base64 characters using these indices.
..and heres a quick diagram to explain that:</p>

<p><img src="images/openacc/ASCII_to_b64.PNG" title="Figure 1: Hex to Base64" alt="Diagram showing Hex to Base64 conversion" /></p>
]]></content>
  </entry>
  
</feed>
